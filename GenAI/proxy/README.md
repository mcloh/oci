# OCI GenAI Proxy API

Proxy compat√≠vel com OpenAI v1 para modelos e agents da Oracle Cloud Infrastructure (OCI) GenAI.

---

## üöÄ In√≠cio R√°pido

### **1. Configurar Modelos**

Edite `llm_models.json`:

```json
{
  "gpt5": {
    "id": "ocid1.generativeaimodel.oc1.us-chicago-1.amaaa...",
    "region": "us-chicago-1",
    "compartmentId": "ocid1.compartment.oc1..aaaaaa...",
    "type": "model"
  },
  "my-agent": {
    "id": "ocid1.generativeaiagentendpoint.oc1.us-chicago-1.amaaa...",
    "region": "us-chicago-1",
    "compartmentId": "ocid1.compartment.oc1..aaaaaa...",
    "type": "agent"
  }
}
```

### **2. Configurar Credenciais OCI**

Edite `credentials.conf`:

```ini
[DEFAULT]
user=ocid1.user.oc1..aaaaaa...
fingerprint=aa:bb:cc:dd:ee:ff:00:11:22:33:44:55:66:77:88:99
tenancy=ocid1.tenancy.oc1..aaaaaa...
region=us-chicago-1
key_file=/path/to/oci_api_key.pem
```

### **3. Iniciar API**

```bash
python3.11 app.py
```

API dispon√≠vel em: `http://localhost:8000`

---

## üìã Endpoints Dispon√≠veis

### **Compat√≠veis com OpenAI v1:**
- `POST /genai/{model}/v1/chat/completions` - Chat completion
- `POST /genai/{model}/v1/completions` - Text completion
- `GET /genai/{model}/v1/models` - Informa√ß√µes do modelo
- `POST /genai/{model}/v1/embeddings` - Embeddings (Cohere)

### **Diretos OCI:**
- `POST /genai/{model}/session` - Criar sess√£o (agents)
- `POST /genai/{model}/chat` - Chat com agent
- `POST /genai/{model}/inference` - Infer√™ncia direta (models)

---

## üí¨ Exemplos de Uso

### **1. Chat com Model (OpenAI v1)**

```python
import requests

response = requests.post(
    "http://localhost:8000/genai/gpt5/v1/chat/completions",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "messages": [
            {"role": "user", "content": "Explique computa√ß√£o qu√¢ntica"}
        ],
        "temperature": 0.7,
        "max_tokens": 500
    }
)

data = response.json()
print(data["choices"][0]["message"]["content"])
print(f"Tokens: {data['usage']['total_tokens']}")
```

---

### **2. Chat com Agent (Modo Autom√°tico)** ‚≠ê

```python
import requests

# Primeira mensagem
response = requests.post(
    "http://localhost:8000/genai/my-agent/chat",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "channel": "web-app",
        "cuid": "user-12345",
        "userMessage": "Ol√°, preciso de ajuda"
    }
)

data = response.json()
print(data["agentResponse"]["content"][0]["text"])
print(f"Sess√£o: {data['sessionInfo']['sessionId']}")
print(f"Reutilizada: {data['sessionInfo']['reused']}")

# Segunda mensagem (mesma sess√£o - autom√°tico!)
response2 = requests.post(
    "http://localhost:8000/genai/my-agent/chat",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "channel": "web-app",
        "cuid": "user-12345",
        "userMessage": "Qual √© o status do pedido #12345?"
    }
)

data2 = response2.json()
print(data2["agentResponse"]["content"][0]["text"])
print(f"Reutilizada: {data2['sessionInfo']['reused']}")  # True
```

**Benef√≠cios:**
- ‚úÖ Gerenciamento autom√°tico de sess√£o
- ‚úÖ Retry autom√°tico em erro 409
- ‚úÖ Cache local com TTL de 2h

---

### **3. Chat com Agent (Modo Manual)**

```python
import requests

# Passo 1: Criar sess√£o
session_resp = requests.post(
    "http://localhost:8000/genai/my-agent/session",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "channel": "web-app",
        "cuid": "user-12345"
    }
)

session_id = session_resp.json()["id"]

# Passo 2: Enviar mensagem
chat_resp = requests.post(
    "http://localhost:8000/genai/my-agent/chat",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "sessionId": session_id,
        "userMessage": "Ol√°"
    }
)

response = chat_resp.json()["agentResponse"]["content"][0]["text"]
print(response)
```

---

### **4. Infer√™ncia Direta (OCI)**

```python
import requests

response = requests.post(
    "http://localhost:8000/genai/gpt5/inference",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "prompt": "Traduza para ingl√™s: Ol√°, mundo!",
        "temperature": 0.3,
        "max_tokens": 100
    }
)

data = response.json()
print(data["response"]["text"])
print(data["response"]["finish_reason"])
```

---

### **5. Streaming**

```python
import requests

response = requests.post(
    "http://localhost:8000/genai/gpt5/v1/chat/completions",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "messages": [{"role": "user", "content": "Conte uma hist√≥ria"}],
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

---

### **6. Embeddings**

```python
import requests

response = requests.post(
    "http://localhost:8000/genai/gpt5/v1/embeddings",
    headers={"Authorization": "Bearer YOUR_API_KEY"},
    json={
        "input": "Texto para gerar embedding",
        "model": "cohere.embed-multilingual-v3.0"
    }
)

data = response.json()
embedding = data["data"][0]["embedding"]
print(f"Dimens√µes: {len(embedding)}")
```

---

## üîë Autentica√ß√£o

Configure `API_KEY` no c√≥digo ou use vari√°vel de ambiente:

```bash
export API_KEY="your-secret-key"
python3.11 app.py
```

Envie em todas as requisi√ß√µes:

```bash
# Op√ß√£o 1: Header Authorization
Authorization: Bearer YOUR_API_KEY

# Op√ß√£o 2: Header X-API-Key
X-API-Key: YOUR_API_KEY
```

---

## üìä Par√¢metros Comuns

### **Chat Completions:**

| Par√¢metro | Tipo | Descri√ß√£o |
|-----------|------|-----------|
| `messages` | array | Lista de mensagens (role + content) |
| `temperature` | float | Aleatoriedade (0.0 a 2.0) |
| `max_tokens` | integer | M√°ximo de tokens na resposta |
| `top_p` | float | Nucleus sampling |
| `stream` | boolean | Streaming (Server-Sent Events) |

### **Chat com Agent (Modo Autom√°tico):**

| Par√¢metro | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-----------|------|-------------|-----------|
| `channel` | string | ‚úÖ | Canal (ex: `web-app`, `mobile-app`) |
| `cuid` | string | ‚úÖ | Customer User ID |
| `userMessage` | string | ‚úÖ | Mensagem do usu√°rio |

### **Infer√™ncia Direta:**

| Par√¢metro | Tipo | Descri√ß√£o |
|-----------|------|-----------|
| `prompt` | string | Texto de entrada |
| `temperature` | float | Aleatoriedade (0.0 a 2.0) |
| `max_tokens` | integer | M√°ximo de tokens |
| `top_p` | float | Nucleus sampling |
| `top_k` | integer | Top-k sampling |

---

## üõ†Ô∏è Configura√ß√£o Avan√ßada

### **Modo de Teste**

```bash
export TEST_MODE=true
python3.11 app.py
```

Retorna respostas simuladas sem chamar OCI.

### **Porta Customizada**

```bash
python3.11 app.py --port 9000
```

### **CORS**

CORS habilitado por padr√£o para `*`. Edite `app.py` para restringir.

---

## üìù Estrutura de Resposta

### **Chat Completion (OpenAI v1):**

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1699999999,
  "model": "gpt5",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Resposta do modelo..."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 15,
    "completion_tokens": 120,
    "total_tokens": 135
  }
}
```

### **Chat com Agent (Modo Autom√°tico):**

```json
{
  "agentResponse": {
    "role": "ASSISTANT",
    "content": [
      {
        "text": "Resposta do agent..."
      }
    ],
    "timeCreated": "2024-11-14T10:05:00.000Z"
  },
  "sessionInfo": {
    "sessionId": "ocid1.generativeaiagentsession.oc1.us-chicago-1.amaaa...",
    "sessionKey": "web-app:user-12345",
    "reused": true
  }
}
```

### **Infer√™ncia Direta:**

```json
{
  "response": {
    "text": "Resposta do modelo...",
    "finish_reason": "STOP"
  }
}
```

---

## ‚ö†Ô∏è Erros Comuns

### **1. Modelo n√£o encontrado**

```json
{"error": "Modelo 'xxx' n√£o encontrado no arquivo de configura√ß√£o"}
```

**Solu√ß√£o:** Adicione o modelo em `llm_models.json`.

---

### **2. Tipo incorreto**

```json
{"error": "Modelo 'gpt5' n√£o √© um agent. Use type='agent' no JSON."}
```

**Solu√ß√£o:** Verifique o campo `type` no `llm_models.json`.

---

### **3. Sess√£o expirada (modo manual)**

```json
{
  "error": "Sess√£o inv√°lida ou expirada",
  "suggestion": "Use modo autom√°tico com 'channel' e 'cuid'"
}
```

**Solu√ß√£o:** Use modo autom√°tico ou crie nova sess√£o.

---

### **4. Autentica√ß√£o inv√°lida**

```json
{"error": "API Key inv√°lida"}
```

**Solu√ß√£o:** Verifique header `Authorization` ou `X-API-Key`.

---

## üîÑ Compara√ß√£o: Models vs Agents

| Aspecto | Models | Agents |
|---------|--------|--------|
| **Endpoint OpenAI** | `/v1/chat/completions` | `/v1/chat/completions` |
| **Endpoint OCI** | `/inference` | `/chat` |
| **Sess√£o** | N√£o | Sim (gerenciada automaticamente) |
| **Token usage** | ‚úÖ Sim | ‚ùå N√£o |
| **Contexto** | Stateless | Mantido na sess√£o |
| **Streaming** | ‚úÖ Sim | ‚úÖ Sim |

---

## üìö Documenta√ß√£o Completa

Para documenta√ß√£o detalhada, consulte:
- `CHAT_FUSIONADO_v2.0.4.md` - Endpoint /chat com gerenciamento autom√°tico
- `ENDPOINTS_OCI_DIRETOS.md` - Endpoints diretos OCI
- `EXPLICACAO_CHAMADAS_OCI.md` - Detalhes t√©cnicos internos
- `CHANGELOG.md` - Hist√≥rico de vers√µes

---

## üéØ Resumo R√°pido

### **Para Models:**
```python
# OpenAI v1 (recomendado)
POST /genai/{model}/v1/chat/completions
Body: {"messages": [...]}

# OCI direto
POST /genai/{model}/inference
Body: {"prompt": "..."}
```

### **Para Agents:**
```python
# Modo autom√°tico (recomendado)
POST /genai/{agent}/chat
Body: {"channel": "...", "cuid": "...", "userMessage": "..."}

# Modo manual
POST /genai/{agent}/session  # Criar sess√£o
POST /genai/{agent}/chat      # Enviar mensagem
Body: {"sessionId": "...", "userMessage": "..."}
```

---

## üì¶ Vers√£o

**v2.0.3** - Novembro 2024

**Funcionalidades:**
- ‚úÖ Compatibilidade OpenAI v1
- ‚úÖ Endpoints diretos OCI
- ‚úÖ Gerenciamento autom√°tico de sess√£o (agents)
- ‚úÖ Retry autom√°tico de erro 409
- ‚úÖ Streaming
- ‚úÖ Token usage
- ‚úÖ Embeddings (Cohere)
- ‚úÖ Upload de arquivos

---

## üöÄ Suporte

Para d√∫vidas ou problemas, consulte a documenta√ß√£o completa ou abra uma issue no reposit√≥rio.
