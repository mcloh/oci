#!/usr/bin/env python3
"""
Cliente MCP que interage com o usu√°rio via chat usando LLM.
Interpreta a opera√ß√£o matem√°tica desejada e executa atrav√©s do servidor MCP.
"""

import asyncio
import json
from typing import Optional
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI


# Configura√ß√£o do LLM
API_BASE_URL = "https://api.xptoai.com.br/genai/grokcode/v1"
API_KEY = "sua chave de API para o endopoint do LLM"
MODEL_NAME = "grokcode"  # Modelo padr√£o, pode ser ajustado


class MCPChatClient:
    """Cliente de chat que integra MCP com LLM."""
    
    def __init__(self):
        self.client = OpenAI(
            base_url=API_BASE_URL,
            api_key=API_KEY
        )
        self.session: Optional[ClientSession] = None
        self.available_tools = []
        self.conversation_history = []
        
    async def connect_to_server(self):
        """Conecta ao servidor MCP."""
        server_params = StdioServerParameters(
            command="python3",
            args=["mcp_server.py"],
            env=None
        )
        
        # stdio_client retorna um context manager ass√≠ncrono
        self.stdio_context = stdio_client(server_params)
        self.stdio, self.write = await self.stdio_context.__aenter__()
        self.session = ClientSession(self.stdio, self.write)
        
        await self.session.__aenter__()
        
        # Inicializar sess√£o
        await self.session.initialize()
        
        # Obter lista de ferramentas dispon√≠veis
        tools_list = await self.session.list_tools()
        self.available_tools = tools_list.tools
        
        print(f"‚úì Conectado ao servidor MCP")
        print(f"‚úì Ferramentas dispon√≠veis: {[tool.name for tool in self.available_tools]}\n")
    
    def format_tools_for_openai(self) -> list:
        """Formata as ferramentas MCP para o formato OpenAI."""
        openai_tools = []
        for tool in self.available_tools:
            openai_tools.append({
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": tool.inputSchema
                }
            })
        return openai_tools
    
    async def call_mcp_tool(self, tool_name: str, arguments: dict) -> str:
        """Chama uma ferramenta no servidor MCP."""
        result = await self.session.call_tool(tool_name, arguments)
        
        # Extrair o conte√∫do de texto do resultado
        if result.content and len(result.content) > 0:
            return result.content[0].text
        return json.dumps({"error": "Nenhum resultado retornado"})
    
    async def chat(self, user_message: str) -> str:
        """Processa uma mensagem do usu√°rio e retorna a resposta do LLM."""
        
        # Adicionar mensagem do usu√°rio ao hist√≥rico
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })
        
        # Preparar mensagens para o LLM
        messages = [
            {
                "role": "system",
                "content": (
                    "Voc√™ √© um assistente matem√°tico inteligente que ajuda usu√°rios a realizar opera√ß√µes matem√°ticas. "
                    "Voc√™ tem acesso a 4 ferramentas: soma, subtra√ß√£o, multiplica√ß√£o e divis√£o. "
                    "\n\n"
                    "Seu objetivo √©:\n"
                    "1. Interpretar qual opera√ß√£o matem√°tica o usu√°rio deseja realizar atrav√©s da conversa natural\n"
                    "2. Identificar os dois n√∫meros que o usu√°rio quer usar\n"
                    "3. Chamar a ferramenta apropriada com os n√∫meros corretos\n"
                    "4. Apresentar o resultado de forma clara e amig√°vel\n"
                    "\n"
                    "Exemplos de interpreta√ß√£o:\n"
                    "- 'Quanto √© 5 mais 3?' ‚Üí usar ferramenta 'soma' com 5 e 3\n"
                    "- 'Subtraia 10 de 25' ‚Üí usar ferramenta 'subtracao' com 25 e 10\n"
                    "- 'Multiplique 7 por 8' ‚Üí usar ferramenta 'multiplicacao' com 7 e 8\n"
                    "- 'Divida 20 por 4' ‚Üí usar ferramenta 'divisao' com 20 e 4\n"
                    "- '15 menos 7' ‚Üí usar ferramenta 'subtracao' com 15 e 7\n"
                    "\n"
                    "Se o usu√°rio pedir uma opera√ß√£o que n√£o est√° dispon√≠vel (como pot√™ncia, raiz quadrada, etc.), "
                    "informe educadamente que apenas as 4 opera√ß√µes b√°sicas est√£o implementadas. "
                    "\n"
                    "Seja conversacional, natural e prestativo na intera√ß√£o."
                )
            }
        ] + self.conversation_history
        
        # Fazer chamada ao LLM com ferramentas
        openai_tools = self.format_tools_for_openai()
        
        response = self.client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            tools=openai_tools if openai_tools else None,
            tool_choice="auto" if openai_tools else None
        )
        
        assistant_message = response.choices[0].message
        
        # Verificar se o LLM quer chamar ferramentas
        if assistant_message.tool_calls:
            # Adicionar a resposta do assistente ao hist√≥rico
            self.conversation_history.append({
                "role": "assistant",
                "content": assistant_message.content,
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    }
                    for tc in assistant_message.tool_calls
                ]
            })
            
            # Executar as ferramentas solicitadas
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                print(f"üîß Executando ferramenta: {function_name}")
                print(f"   Argumentos: {function_args}")
                
                # Chamar a ferramenta MCP
                tool_result = await self.call_mcp_tool(function_name, function_args)
                
                # Verificar se houve erro no resultado
                try:
                    result_data = json.loads(tool_result)
                    if "error" in result_data:
                        print(f"   ‚ö†Ô∏è  Erro: {result_data['error']}")
                    else:
                        print(f"   ‚úì Resultado: {result_data.get('resultado', tool_result)}")
                except:
                    print(f"   Resultado: {tool_result}")
                
                print()
                
                # Adicionar resultado da ferramenta ao hist√≥rico
                self.conversation_history.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": tool_result
                })
            
            # Fazer nova chamada ao LLM com os resultados das ferramentas
            messages = [
                {
                    "role": "system",
                    "content": (
                        "Voc√™ √© um assistente matem√°tico inteligente que ajuda usu√°rios a realizar opera√ß√µes matem√°ticas. "
                        "Voc√™ tem acesso a 4 ferramentas: soma, subtra√ß√£o, multiplica√ß√£o e divis√£o. "
                        "\n\n"
                        "Seu objetivo √©:\n"
                        "1. Interpretar qual opera√ß√£o matem√°tica o usu√°rio deseja realizar atrav√©s da conversa natural\n"
                        "2. Identificar os dois n√∫meros que o usu√°rio quer usar\n"
                        "3. Chamar a ferramenta apropriada com os n√∫meros corretos\n"
                        "4. Apresentar o resultado de forma clara e amig√°vel\n"
                        "\n"
                        "Exemplos de interpreta√ß√£o:\n"
                        "- 'Quanto √© 5 mais 3?' ‚Üí usar ferramenta 'soma' com 5 e 3\n"
                        "- 'Subtraia 10 de 25' ‚Üí usar ferramenta 'subtracao' com 25 e 10\n"
                        "- 'Multiplique 7 por 8' ‚Üí usar ferramenta 'multiplicacao' com 7 e 8\n"
                        "- 'Divida 20 por 4' ‚Üí usar ferramenta 'divisao' com 20 e 4\n"
                        "- '15 menos 7' ‚Üí usar ferramenta 'subtracao' com 15 e 7\n"
                        "\n"
                        "Se o usu√°rio pedir uma opera√ß√£o que n√£o est√° dispon√≠vel (como pot√™ncia, raiz quadrada, etc.), "
                        "informe educadamente que apenas as 4 opera√ß√µes b√°sicas est√£o implementadas. "
                        "\n"
                        "Se houver erro na execu√ß√£o (como divis√£o por zero), explique o erro de forma educada e sugira uma alternativa. "
                        "\n"
                        "Seja conversacional, natural e prestativo na intera√ß√£o."
                    )
                }
            ] + self.conversation_history
            
            final_response = self.client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages
            )
            
            final_message = final_response.choices[0].message.content
            
            # Adicionar resposta final ao hist√≥rico
            self.conversation_history.append({
                "role": "assistant",
                "content": final_message
            })
            
            return final_message
        
        else:
            # N√£o h√° chamadas de ferramentas, apenas resposta textual
            response_text = assistant_message.content or ""
            
            self.conversation_history.append({
                "role": "assistant",
                "content": response_text
            })
            
            return response_text
    
    async def close(self):
        """Fecha a conex√£o com o servidor MCP."""
        if self.session:
            await self.session.__aexit__(None, None, None)
        if hasattr(self, 'stdio_context'):
            await self.stdio_context.__aexit__(None, None, None)


async def main():
    """Fun√ß√£o principal que executa o chat interativo."""
    print("=" * 60)
    print("  Chat com AI Agent - Opera√ß√µes Matem√°ticas")
    print("=" * 60)
    print()
    
    client = MCPChatClient()
    
    try:
        # Conectar ao servidor MCP
        await client.connect_to_server()
        
        print("üí¨ Iniciando conversa com o assistente...")
        print("   (Digite 'sair' para encerrar)\n")
        print("-" * 60)
        
        # Loop de chat interativo
        while True:
            # Obter entrada do usu√°rio
            user_input = input("\nüë§ Voc√™: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['sair', 'exit', 'quit']:
                print("\nüëã Encerrando chat. At√© logo!")
                break
            
            # Processar mensagem
            print("\nü§ñ Assistente: ", end="", flush=True)
            response = await client.chat(user_input)
            print(response)
            print("-" * 60)
    
    except KeyboardInterrupt:
        print("\n\nüëã Chat interrompido. At√© logo!")
    
    except Exception as e:
        print(f"\n‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Fechar conex√£o
        await client.close()


if __name__ == "__main__":
    asyncio.run(main())
